{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopfield Network With Hashing - Hopfield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a memory mechanism in a form of a Hopfield network. The stored items are called memory patterns. They are retrieved by a process of the input that is presented to the network dynamics which at some time step reaches a fixed stable point. This means that the input item has been recognized (i.e. there is a memory pattern identical or very similar to it).\n",
    "\n",
    "Even noisy sounds or those corrupted to some extent can be accessed. In other words, if the input is $x_1 + \\delta$ and the stored item is $x_1$, the network will still reach the fixed point of $x_1$ if $\\delta$ is small enough.\n",
    "\n",
    "Additionally, for storage purposes, sounds are transformed each into a hash - with this we reduce their dimensionality. This means we increase the storage capacity. \n",
    "\n",
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we load the neccessary dependencies.\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import librosa\n",
    "import scipy.io.wavfile as wav\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with some wav files to test this script.\n",
    "\n",
    "folder_train = \"./wavs/\"\n",
    "\n",
    "test_folder = \"./test_wavs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features\n",
    "\n",
    "First, we will transform our .wav files into features, in this case MFCCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mfcc(folder):\n",
    "    \"\"\"\n",
    "    Go through the folder and find all (and only) files ending with .wav\n",
    "    Here, we transform each .wav file into MFCCs and then flatten them into one vector.\n",
    "    We do this because we want one hash per .wav file.\n",
    "    \n",
    "    Any file shorter than the longest file in the folder will be padded with values 0,\n",
    "    so that all concatenated file vectors are of the same length.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : path to folder with wav sounds\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    a list of flattened MFCC vectors\n",
    "    \"\"\"\n",
    "    vectors = []\n",
    "    for file in glob.glob(folder + \"*.wav\", recursive=True):\n",
    "        y, sr = librosa.load(file)\n",
    "        mfcc_feat = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        vect = mfcc_feat.flatten()\n",
    "        vectors.append(vect)\n",
    "        print(len(vectors), \" mfccs done\")\n",
    "    # find the largest vector\n",
    "    max_length = len(max(vectors, key=lambda p: len(p)))\n",
    "    # append zeros to all the other vectors\n",
    "    for i in range(len(vectors)):\n",
    "        vectors[i] = np.pad(vectors[i], (0,max_length-len(vectors[i])))\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing of features\n",
    "\n",
    "Now we will use these features and transform them into hash vectors, which we will use to store in our memory. We do this to facilitate memory storage: hashes are vectors with reduced dimensionality, with values mostly equal to 0 and a few of them equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_dim(d,k,m,seed):  \n",
    "    \n",
    "    \"\"\"\n",
    "    Define hash parameters.\n",
    "    The hash will be a matrix of the dimension = k*m\n",
    "    We choose a random number k of units of the vector.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    d : num\n",
    "        Length of a random vector being stored\n",
    "    k : num\n",
    "        Number of units we randomly choose of the vector\n",
    "    m : num\n",
    "        Number of times we will  do the hashing for some vector\n",
    "    seed : num\n",
    "        We always want the same units randomly chosen\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    a numpy array \n",
    "        p of dimensions [k,m] represents randomly chosen dimensions\n",
    "    \n",
    "    \"\"\"   \n",
    "    assert k <= d\n",
    "    p = np.zeros((m,k,))\n",
    "    np.random.seed(seed)\n",
    "    for i in range(m):\n",
    "        p[i] = np.random.permutation(d)[:k]\n",
    "    return p\n",
    "\n",
    "    \n",
    "def get_hash(vector, k, m, p): \n",
    "    \"\"\"\n",
    "    Transform a vector of speech into a hash\n",
    "    The hash will be a matrix of the dimension = k*m\n",
    "    \n",
    "    Once we have chosen k random dimensions, we look for the highest \n",
    "    value and turn it into 1. Everything else is 0.\n",
    "    We thus get sparse matrices.\n",
    "    We do this m times. Final output is h=k*m.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    vector : np.array\n",
    "        Features (i.e. MFCC) of some sound with dim = 1*n\n",
    "    k : num\n",
    "        Number of units we randomly choose of the vector\n",
    "    m : num\n",
    "        Number of times we will do the hashing for some vector.\n",
    "    p : numpy array\n",
    "        p of dimensions [k,m] represents randomly chosen dimensions\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    a numpy array h of size [1, k*m]\n",
    "    \"\"\"\n",
    "    h = np.zeros((m,k,))\n",
    "    for i in range(m):\n",
    "        p_line = p[i].astype(int)\n",
    "        ix = np.argmax(vector[p_line])\n",
    "        hi = np.zeros(k)\n",
    "        hi[ix] = 1\n",
    "        h[i] = hi\n",
    "    h = np.hstack(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test hash:  [1. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "expected_h = np.array([[1,0,0],[0,0,1]]).flatten()\n",
    "vector = np.array([6,4,5,9,2])\n",
    "# %timeit hash_dim(len(vector),3,2,2).astype(int)\n",
    "p0 = hash_dim(len(vector),3,2,2).astype(int)\n",
    "print(\"This is a test hash: \", get_hash(vector, 3, 2, p0))\n",
    "assert get_hash(vector, 3, 2, p0).all() == expected_h.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory storage\n",
    "\n",
    "We must now construct our neuron weight matrix that reopresents the connections between neurons of our memory network.\n",
    "We will first initialize our matrix representing the synaptic weights and then enable subsequent addition of new memories.\n",
    "\n",
    "Synaptic weight matrix is a matrix that represents connections between each and every neuron. Every neuron has a state which can be active or inactive. Initialization of synaptic weights will make the connection between two neurons such that it is strengthened if both neurons are active (and the other way round, it will weaken the connection if one of the neurons is inactive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(N, V=None):\n",
    "    \"\"\"\n",
    "    Eq. (2) from [1]\n",
    "    \n",
    "    Initialize synaptic weights in form of matrix T (symmetric recurrent weight matrix).\n",
    "    This is a memory storage.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : num\n",
    "        number of neurons\n",
    "    V : list\n",
    "        list of vectors in a hash form\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    a numpy array T of shape (N, N)\n",
    "        Memory storage in form of a matrix (synaptic weights)\n",
    "        Its dimensions are determined by N=k*m (hash parameters)\n",
    "    \"\"\"\n",
    "    \n",
    "    %timeit\n",
    "    T = np.zeros((N,N))\n",
    "    if V != None:\n",
    "        for vect in V:\n",
    "            #outer_prod = np.outer((2*vect - 1),(2*vect - 1))\n",
    "            T = add_memory(T, vect)\n",
    "            #T += outer_prod\n",
    "        \n",
    "    return T\n",
    "\n",
    "\n",
    "def add_memory(T, new_memory):\n",
    "    \"\"\"\n",
    "    Eq. (2) from [1]\n",
    "    \n",
    "    Update synaptic weights in form of matrix T (symmetric recurrent weight matrix) when adding new memory.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    T : a numpy array T_sum of shape (N, N)\n",
    "        Initialized memory storage in form of a matrix (synaptic weights)\n",
    "    new_memory : numpy array of shape (1,N)\n",
    "        a vector we wish to store\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    a numpy array T of shape (N, N)\n",
    "        Renewed memory storage in form of a matrix (synaptic weights)\n",
    "        Its dimensions are determined by N=k*m (hash parameters)\n",
    "    \"\"\"\n",
    "    \n",
    "    outer_prod = np.outer((2*new_memory - 1),(2*new_memory - 1))\n",
    "    T += outer_prod\n",
    "        \n",
    "    return T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory retrieval\n",
    "\n",
    "When we want to retrieve a memory, we start with some initial state and then observe the dynamics of the system - if it reaches a stable point, we have accessed to either some stored memory or to a state by default where we can end up if we have not stored something similar to initial state.\n",
    "\n",
    "In other words, we can represent this as a surface with differently sized bumps. We put a ball on this surface and it will roll into the nearest pit, unless we already put it on the already lowest point of the pit.\n",
    "\n",
    "To check whether this lowest point (or stable/fixed point) was reached, we check stability of being there - have we been here a few moments ago? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy(T, V):\n",
    "    \"\"\"\n",
    "    Eq. (7) from [1]\n",
    "    \n",
    "    Energy of the system is a monotonically decreasing function.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    T : a numpy array of shape (N, N)\n",
    "        Memory in form of a matrix (synaptic weights)\n",
    "    V : numpy array\n",
    "        a list of states of activation\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    num\n",
    "        Energy of the system\n",
    "    \"\"\"\n",
    "    E = 0\n",
    "    for i in range(T.shape[0]):\n",
    "        for j in range(T.shape[1]):\n",
    "            E -= 1/2 * (T[i,j] * V[i] * V[j])\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_memory(T, V0, U=0, full_trace=True, SEED=27, conv_check_spacing=100):\n",
    "    \"\"\"\n",
    "    Eq. (1) from [1]\n",
    "    \n",
    "    To retrieve a memory, we want to find the stable/fixed point of the \n",
    "    dynamic network represented by matrix T (synaptic weights in which\n",
    "    the memory is stored) when starting from vector V.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T : a numpy array T of shape (N, N)\n",
    "        Memory in form of a matrix (synaptic weights)\n",
    "    V0 : a numpy array of shape (1, N)\n",
    "        a vector with which we initialize the network activity (check if it is stored in T)\n",
    "    U : num\n",
    "        a scalar representing the threshold of neuron's state of activity.\n",
    "        Set to 0 by default.\n",
    "        \"With a threshold of 0,the system behaves as a forced categorizer.\" [1]\n",
    "    full_trace : boolean\n",
    "        Set to True by default. This means we will keep all the changes of the initial neuron states\n",
    "        as they change through time.\n",
    "    SEED : num\n",
    "        Used for the random choices of indices, which we can control for replication by always \n",
    "        setting the seed to the same number.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    a numpy array of shape (1, N)\n",
    "        We return the new / denoised V\n",
    "    \"\"\"\n",
    "    random.seed(SEED)\n",
    "    \n",
    "    V = V0\n",
    "    if full_trace:\n",
    "        V_history = [V.copy()]\n",
    "    \n",
    "    while not has_converged(T, U, V):\n",
    "        for _ in range(conv_check_spacing):\n",
    "            i = random.randrange(V.shape[0])\n",
    "            V[i] = update_neuron(T, U, V, i)\n",
    "            if full_trace:\n",
    "                V_history.append(V.copy())\n",
    "\n",
    "    if full_trace:\n",
    "        return V_history\n",
    "    else:\n",
    "        return V\n",
    "\n",
    "\n",
    "def update_neuron(T, U, V, i):\n",
    "    \"\"\"\n",
    "    We calculate sum_j {T_ji * V[j]}, where T_ij is our synaptic weight between neuron j and i\n",
    "    and V[j] is a j-th neuron state \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    T : a numpy array T_sum of shape (N, N)\n",
    "        Initialized memory storage in form of a matrix (synaptic weights)\n",
    "    V : num\n",
    "        a scalar representing the neural network state\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    num\n",
    "        We return the sum of all components of i-th row of T, each multiplied by V_j\n",
    "    \"\"\"\n",
    "    new_V_i = check_threshold(sum(T[i] * V), U)\n",
    "    return new_V_i\n",
    "\n",
    "\n",
    "\n",
    "def check_threshold(membrane_potential, U):\n",
    "    \"\"\"\n",
    "    Check whether the sum of T_ij * V_j is bigger or smaller than the threshold U\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    TV_sum : num\n",
    "        Sum over T_ij * V_j\n",
    "    U : num\n",
    "        a scalar representing a threshold of neuron's state of activity\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    num\n",
    "        We return either 0 or 1, depending on TV_sum being smaller\n",
    "        or larger than the threshold U\n",
    "    \"\"\"\n",
    "    if membrane_potential > U:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "def has_converged(T, U, V):\n",
    "    \"\"\"\n",
    "    Check whether the new V_i is the same as i-th value of V\n",
    "    and whether the current energy is equal to the previous one\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    V_i : num\n",
    "        state of V's i-th neuron (either active: 1, or inactive: 0)\n",
    "    V : num\n",
    "        a numpy array representing all current neurons' states of activity\n",
    "    i : num\n",
    "        current randomly chosen index\n",
    "    E_list : list\n",
    "        list of all energy values so far\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    boolean\n",
    "        We return False if we satisfy at least one of the conditions,\n",
    "        else we return True\n",
    "    \"\"\"\n",
    "    converged = True\n",
    "    for i, V_i in enumerate(V):\n",
    "        updated_V_i = update_neuron(T, U, V, i)\n",
    "        if updated_V_i != V_i:\n",
    "            converged = False\n",
    "            break\n",
    "    return converged    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy T matrix: \n",
      " [[ 2. -2.]\n",
      " [-2.  2.]]\n",
      "Retrieved memory of [0,0] - unstored:\n",
      " [array([0, 0])]\n",
      "Retrieved memory of [1,1] - unstored:\n",
      " [array([1, 1]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0])]\n",
      "Retrieved memory of [9,9] - unstored:\n",
      " [array([9, 9]), array([9, 0]), array([9, 0]), array([9, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0]), array([1, 0])]\n",
      "Retrieved memory of [0,1] - stored:\n",
      " [array([0, 1])]\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "toy_V1 = np.array([0,1])\n",
    "toy_V2 = np.array([1,0])\n",
    "# %timeit initialize_network(2, [toy_V1, toy_V2])\n",
    "toy_T = initialize_network(2, [toy_V1, toy_V2])\n",
    "print(\"Toy T matrix: \\n\", toy_T)\n",
    "print(\"Retrieved memory of [0,0] - unstored:\\n\", retrieve_memory(toy_T, np.array([0,0])))\n",
    "print(\"Retrieved memory of [1,1] - unstored:\\n\", retrieve_memory(toy_T, np.array([1,1])))\n",
    "print(\"Retrieved memory of [9,9] - unstored:\\n\", retrieve_memory(toy_T, np.array([9,9])))\n",
    "print(\"Retrieved memory of [0,1] - stored:\\n\", retrieve_memory(toy_T, toy_V1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing \n",
    "\n",
    "We can now inspect our memory network and test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  mfccs done\n",
      "2  mfccs done\n",
      "3  mfccs done\n",
      "4  mfccs done\n",
      "5  mfccs done\n",
      "6  mfccs done\n",
      "7  mfccs done\n",
      "8  mfccs done\n",
      "9  mfccs done\n",
      "10  mfccs done\n",
      "11  mfccs done\n",
      "12  mfccs done\n",
      "13  mfccs done\n",
      "14  mfccs done\n",
      "15  mfccs done\n",
      "16  mfccs done\n",
      "17  mfccs done\n",
      "18  mfccs done\n",
      "19  mfccs done\n",
      "20  mfccs done\n",
      "21  mfccs done\n",
      "22  mfccs done\n",
      "23  mfccs done\n",
      "24  mfccs done\n",
      "25  mfccs done\n",
      "26  mfccs done\n",
      "27  mfccs done\n",
      "28  mfccs done\n",
      "29  mfccs done\n",
      "30  mfccs done\n",
      "31  mfccs done\n",
      "32  mfccs done\n",
      "33  mfccs done\n",
      "34  mfccs done\n",
      "35  mfccs done\n",
      "36  mfccs done\n",
      "37  mfccs done\n",
      "38  mfccs done\n",
      "39  mfccs done\n",
      "40  mfccs done\n",
      "41  mfccs done\n",
      "42  mfccs done\n",
      "43  mfccs done\n",
      "44  mfccs done\n",
      "45  mfccs done\n",
      "46  mfccs done\n",
      "47  mfccs done\n",
      "48  mfccs done\n",
      "49  mfccs done\n",
      "50  mfccs done\n",
      "51  mfccs done\n",
      "52  mfccs done\n",
      "53  mfccs done\n",
      "54  mfccs done\n",
      "55  mfccs done\n",
      "56  mfccs done\n",
      "57  mfccs done\n",
      "58  mfccs done\n",
      "59  mfccs done\n",
      "60  mfccs done\n",
      "61  mfccs done\n",
      "62  mfccs done\n",
      "63  mfccs done\n",
      "64  mfccs done\n",
      "65  mfccs done\n",
      "66  mfccs done\n",
      "67  mfccs done\n",
      "68  mfccs done\n",
      "69  mfccs done\n",
      "70  mfccs done\n",
      "71  mfccs done\n",
      "72  mfccs done\n",
      "73  mfccs done\n",
      "74  mfccs done\n",
      "75  mfccs done\n",
      "76  mfccs done\n",
      "77  mfccs done\n",
      "78  mfccs done\n",
      "79  mfccs done\n",
      "80  mfccs done\n",
      "81  mfccs done\n",
      "82  mfccs done\n",
      "83  mfccs done\n",
      "84  mfccs done\n",
      "85  mfccs done\n",
      "86  mfccs done\n",
      "87  mfccs done\n",
      "88  mfccs done\n",
      "89  mfccs done\n",
      "90  mfccs done\n",
      "91  mfccs done\n",
      "92  mfccs done\n",
      "93  mfccs done\n",
      "94  mfccs done\n",
      "95  mfccs done\n",
      "96  mfccs done\n",
      "97  mfccs done\n",
      "98  mfccs done\n",
      "99  mfccs done\n",
      "100  mfccs done\n",
      "101  mfccs done\n",
      "102  mfccs done\n",
      "103  mfccs done\n",
      "104  mfccs done\n",
      "105  mfccs done\n",
      "106  mfccs done\n",
      "107  mfccs done\n",
      "108  mfccs done\n",
      "109  mfccs done\n",
      "110  mfccs done\n",
      "111  mfccs done\n",
      "112  mfccs done\n",
      "113  mfccs done\n",
      "114  mfccs done\n",
      "115  mfccs done\n",
      "116  mfccs done\n",
      "117  mfccs done\n",
      "118  mfccs done\n",
      "119  mfccs done\n",
      "120  mfccs done\n",
      "121  mfccs done\n",
      "122  mfccs done\n",
      "123  mfccs done\n",
      "124  mfccs done\n",
      "125  mfccs done\n",
      "126  mfccs done\n",
      "127  mfccs done\n",
      "128  mfccs done\n",
      "129  mfccs done\n",
      "130  mfccs done\n",
      "131  mfccs done\n",
      "132  mfccs done\n",
      "133  mfccs done\n",
      "134  mfccs done\n",
      "135  mfccs done\n",
      "136  mfccs done\n",
      "137  mfccs done\n",
      "138  mfccs done\n",
      "139  mfccs done\n",
      "140  mfccs done\n",
      "141  mfccs done\n",
      "142  mfccs done\n",
      "143  mfccs done\n",
      "144  mfccs done\n",
      "145  mfccs done\n",
      "146  mfccs done\n",
      "147  mfccs done\n",
      "148  mfccs done\n",
      "149  mfccs done\n",
      "150  mfccs done\n",
      "151  mfccs done\n",
      "152  mfccs done\n",
      "153  mfccs done\n",
      "154  mfccs done\n",
      "155  mfccs done\n",
      "156  mfccs done\n",
      "157  mfccs done\n",
      "158  mfccs done\n",
      "159  mfccs done\n",
      "160  mfccs done\n",
      "161  mfccs done\n",
      "162  mfccs done\n",
      "163  mfccs done\n",
      "164  mfccs done\n",
      "165  mfccs done\n",
      "166  mfccs done\n",
      "167  mfccs done\n",
      "168  mfccs done\n",
      "169  mfccs done\n",
      "170  mfccs done\n",
      "171  mfccs done\n",
      "172  mfccs done\n",
      "173  mfccs done\n",
      "174  mfccs done\n",
      "175  mfccs done\n",
      "176  mfccs done\n",
      "177  mfccs done\n",
      "178  mfccs done\n",
      "179  mfccs done\n",
      "180  mfccs done\n",
      "181  mfccs done\n",
      "182  mfccs done\n",
      "183  mfccs done\n",
      "184  mfccs done\n",
      "185  mfccs done\n",
      "186  mfccs done\n",
      "187  mfccs done\n",
      "188  mfccs done\n",
      "189  mfccs done\n",
      "190  mfccs done\n",
      "191  mfccs done\n",
      "192  mfccs done\n",
      "193  mfccs done\n",
      "194  mfccs done\n",
      "195  mfccs done\n",
      "196  mfccs done\n",
      "197  mfccs done\n",
      "198  mfccs done\n",
      "199  mfccs done\n",
      "200  mfccs done\n",
      "201  mfccs done\n",
      "202  mfccs done\n",
      "203  mfccs done\n",
      "204  mfccs done\n",
      "205  mfccs done\n",
      "206  mfccs done\n",
      "207  mfccs done\n",
      "208  mfccs done\n",
      "209  mfccs done\n",
      "210  mfccs done\n",
      "211  mfccs done\n",
      "212  mfccs done\n",
      "213  mfccs done\n",
      "214  mfccs done\n",
      "215  mfccs done\n",
      "216  mfccs done\n",
      "217  mfccs done\n",
      "218  mfccs done\n",
      "219  mfccs done\n",
      "220  mfccs done\n",
      "221  mfccs done\n",
      "222  mfccs done\n",
      "223  mfccs done\n",
      "224  mfccs done\n",
      "225  mfccs done\n",
      "226  mfccs done\n",
      "227  mfccs done\n",
      "228  mfccs done\n",
      "229  mfccs done\n",
      "230  mfccs done\n",
      "231  mfccs done\n",
      "232  mfccs done\n",
      "233  mfccs done\n",
      "234  mfccs done\n",
      "235  mfccs done\n",
      "236  mfccs done\n",
      "237  mfccs done\n",
      "238  mfccs done\n",
      "239  mfccs done\n",
      "240  mfccs done\n",
      "241  mfccs done\n",
      "242  mfccs done\n",
      "243  mfccs done\n",
      "244  mfccs done\n",
      "245  mfccs done\n",
      "246  mfccs done\n",
      "247  mfccs done\n",
      "248  mfccs done\n",
      "249  mfccs done\n",
      "250  mfccs done\n",
      "251  mfccs done\n",
      "252  mfccs done\n",
      "253  mfccs done\n",
      "254  mfccs done\n",
      "255  mfccs done\n",
      "256  mfccs done\n",
      "257  mfccs done\n",
      "258  mfccs done\n",
      "259  mfccs done\n",
      "260  mfccs done\n",
      "261  mfccs done\n",
      "262  mfccs done\n",
      "263  mfccs done\n",
      "264  mfccs done\n",
      "265  mfccs done\n",
      "266  mfccs done\n",
      "267  mfccs done\n",
      "268  mfccs done\n",
      "269  mfccs done\n",
      "270  mfccs done\n",
      "271  mfccs done\n",
      "272  mfccs done\n",
      "273  mfccs done\n",
      "274  mfccs done\n",
      "275  mfccs done\n",
      "276  mfccs done\n",
      "277  mfccs done\n",
      "278  mfccs done\n",
      "279  mfccs done\n",
      "280  mfccs done\n",
      "281  mfccs done\n",
      "282  mfccs done\n",
      "283  mfccs done\n",
      "284  mfccs done\n",
      "285  mfccs done\n",
      "286  mfccs done\n",
      "287  mfccs done\n",
      "288  mfccs done\n",
      "289  mfccs done\n",
      "290  mfccs done\n",
      "291  mfccs done\n",
      "292  mfccs done\n",
      "293  mfccs done\n",
      "294  mfccs done\n",
      "295  mfccs done\n",
      "296  mfccs done\n",
      "297  mfccs done\n",
      "298  mfccs done\n",
      "299  mfccs done\n",
      "300  mfccs done\n",
      "301  mfccs done\n",
      "302  mfccs done\n",
      "303  mfccs done\n",
      "304  mfccs done\n",
      "305  mfccs done\n",
      "306  mfccs done\n",
      "307  mfccs done\n",
      "308  mfccs done\n",
      "309  mfccs done\n",
      "310  mfccs done\n",
      "311  mfccs done\n",
      "312  mfccs done\n",
      "313  mfccs done\n",
      "314  mfccs done\n",
      "315  mfccs done\n",
      "316  mfccs done\n",
      "317  mfccs done\n",
      "318  mfccs done\n",
      "319  mfccs done\n",
      "320  mfccs done\n",
      "321  mfccs done\n",
      "322  mfccs done\n",
      "323  mfccs done\n",
      "324  mfccs done\n",
      "325  mfccs done\n",
      "326  mfccs done\n",
      "327  mfccs done\n",
      "328  mfccs done\n",
      "329  mfccs done\n",
      "330  mfccs done\n",
      "331  mfccs done\n",
      "332  mfccs done\n",
      "333  mfccs done\n",
      "334  mfccs done\n",
      "335  mfccs done\n",
      "336  mfccs done\n",
      "337  mfccs done\n",
      "338  mfccs done\n",
      "339  mfccs done\n",
      "340  mfccs done\n",
      "341  mfccs done\n",
      "342  mfccs done\n",
      "343  mfccs done\n",
      "344  mfccs done\n",
      "345  mfccs done\n",
      "346  mfccs done\n",
      "347  mfccs done\n",
      "348  mfccs done\n",
      "349  mfccs done\n",
      "350  mfccs done\n",
      "351  mfccs done\n",
      "352  mfccs done\n",
      "353  mfccs done\n",
      "354  mfccs done\n",
      "355  mfccs done\n",
      "356  mfccs done\n",
      "357  mfccs done\n",
      "358  mfccs done\n",
      "359  mfccs done\n",
      "360  mfccs done\n",
      "361  mfccs done\n",
      "362  mfccs done\n",
      "363  mfccs done\n",
      "364  mfccs done\n",
      "365  mfccs done\n",
      "366  mfccs done\n",
      "367  mfccs done\n",
      "368  mfccs done\n",
      "369  mfccs done\n",
      "370  mfccs done\n",
      "371  mfccs done\n",
      "372  mfccs done\n",
      "373  mfccs done\n",
      "374  mfccs done\n",
      "375  mfccs done\n",
      "376  mfccs done\n",
      "377  mfccs done\n",
      "378  mfccs done\n",
      "379  mfccs done\n",
      "380  mfccs done\n",
      "381  mfccs done\n",
      "382  mfccs done\n",
      "383  mfccs done\n",
      "384  mfccs done\n",
      "385  mfccs done\n",
      "386  mfccs done\n",
      "387  mfccs done\n",
      "388  mfccs done\n",
      "389  mfccs done\n",
      "390  mfccs done\n",
      "391  mfccs done\n",
      "392  mfccs done\n",
      "393  mfccs done\n",
      "394  mfccs done\n",
      "395  mfccs done\n",
      "396  mfccs done\n",
      "397  mfccs done\n",
      "398  mfccs done\n",
      "399  mfccs done\n",
      "400  mfccs done\n",
      "401  mfccs done\n",
      "402  mfccs done\n",
      "403  mfccs done\n",
      "404  mfccs done\n",
      "405  mfccs done\n",
      "406  mfccs done\n",
      "407  mfccs done\n",
      "408  mfccs done\n",
      "409  mfccs done\n",
      "410  mfccs done\n",
      "411  mfccs done\n",
      "412  mfccs done\n",
      "413  mfccs done\n",
      "414  mfccs done\n",
      "415  mfccs done\n",
      "416  mfccs done\n",
      "417  mfccs done\n",
      "418  mfccs done\n",
      "419  mfccs done\n",
      "420  mfccs done\n",
      "421  mfccs done\n",
      "422  mfccs done\n",
      "423  mfccs done\n",
      "424  mfccs done\n",
      "425  mfccs done\n",
      "426  mfccs done\n",
      "427  mfccs done\n",
      "428  mfccs done\n",
      "429  mfccs done\n",
      "430  mfccs done\n",
      "431  mfccs done\n",
      "432  mfccs done\n",
      "433  mfccs done\n",
      "434  mfccs done\n",
      "435  mfccs done\n",
      "436  mfccs done\n",
      "437  mfccs done\n",
      "438  mfccs done\n",
      "439  mfccs done\n",
      "440  mfccs done\n",
      "441  mfccs done\n",
      "442  mfccs done\n",
      "443  mfccs done\n",
      "444  mfccs done\n",
      "445  mfccs done\n",
      "446  mfccs done\n",
      "447  mfccs done\n",
      "448  mfccs done\n",
      "449  mfccs done\n",
      "450  mfccs done\n",
      "451  mfccs done\n",
      "452  mfccs done\n",
      "453  mfccs done\n",
      "454  mfccs done\n",
      "455  mfccs done\n",
      "456  mfccs done\n",
      "457  mfccs done\n",
      "458  mfccs done\n",
      "459  mfccs done\n",
      "460  mfccs done\n",
      "461  mfccs done\n",
      "462  mfccs done\n",
      "463  mfccs done\n",
      "464  mfccs done\n",
      "465  mfccs done\n",
      "466  mfccs done\n",
      "467  mfccs done\n",
      "468  mfccs done\n",
      "469  mfccs done\n",
      "470  mfccs done\n",
      "471  mfccs done\n",
      "472  mfccs done\n",
      "473  mfccs done\n",
      "474  mfccs done\n",
      "475  mfccs done\n",
      "476  mfccs done\n",
      "477  mfccs done\n",
      "478  mfccs done\n",
      "479  mfccs done\n",
      "480  mfccs done\n",
      "481  mfccs done\n",
      "482  mfccs done\n",
      "483  mfccs done\n",
      "484  mfccs done\n",
      "485  mfccs done\n",
      "486  mfccs done\n",
      "487  mfccs done\n",
      "488  mfccs done\n",
      "489  mfccs done\n",
      "490  mfccs done\n",
      "491  mfccs done\n",
      "492  mfccs done\n",
      "493  mfccs done\n",
      "494  mfccs done\n",
      "495  mfccs done\n",
      "496  mfccs done\n",
      "497  mfccs done\n",
      "498  mfccs done\n",
      "499  mfccs done\n",
      "500  mfccs done\n",
      "501  mfccs done\n",
      "502  mfccs done\n",
      "503  mfccs done\n",
      "504  mfccs done\n",
      "505  mfccs done\n",
      "506  mfccs done\n",
      "507  mfccs done\n",
      "508  mfccs done\n",
      "509  mfccs done\n",
      "510  mfccs done\n",
      "511  mfccs done\n",
      "512  mfccs done\n",
      "513  mfccs done\n",
      "514  mfccs done\n",
      "515  mfccs done\n",
      "516  mfccs done\n",
      "517  mfccs done\n",
      "518  mfccs done\n",
      "519  mfccs done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520  mfccs done\n",
      "521  mfccs done\n",
      "522  mfccs done\n",
      "523  mfccs done\n",
      "524  mfccs done\n",
      "525  mfccs done\n",
      "526  mfccs done\n",
      "527  mfccs done\n",
      "528  mfccs done\n",
      "529  mfccs done\n",
      "530  mfccs done\n",
      "531  mfccs done\n",
      "532  mfccs done\n",
      "533  mfccs done\n",
      "534  mfccs done\n",
      "535  mfccs done\n",
      "536  mfccs done\n",
      "537  mfccs done\n",
      "538  mfccs done\n",
      "539  mfccs done\n",
      "540  mfccs done\n",
      "541  mfccs done\n",
      "542  mfccs done\n",
      "543  mfccs done\n",
      "544  mfccs done\n",
      "545  mfccs done\n",
      "546  mfccs done\n",
      "547  mfccs done\n",
      "548  mfccs done\n",
      "549  mfccs done\n",
      "550  mfccs done\n",
      "551  mfccs done\n",
      "552  mfccs done\n",
      "553  mfccs done\n",
      "554  mfccs done\n",
      "555  mfccs done\n",
      "556  mfccs done\n",
      "557  mfccs done\n",
      "558  mfccs done\n",
      "559  mfccs done\n",
      "560  mfccs done\n",
      "561  mfccs done\n",
      "562  mfccs done\n",
      "563  mfccs done\n",
      "564  mfccs done\n",
      "565  mfccs done\n",
      "566  mfccs done\n",
      "567  mfccs done\n",
      "568  mfccs done\n",
      "569  mfccs done\n",
      "570  mfccs done\n",
      "571  mfccs done\n",
      "572  mfccs done\n",
      "573  mfccs done\n",
      "574  mfccs done\n",
      "575  mfccs done\n",
      "576  mfccs done\n",
      "577  mfccs done\n",
      "578  mfccs done\n",
      "579  mfccs done\n",
      "580  mfccs done\n",
      "581  mfccs done\n",
      "582  mfccs done\n",
      "583  mfccs done\n",
      "584  mfccs done\n",
      "585  mfccs done\n",
      "586  mfccs done\n",
      "587  mfccs done\n",
      "588  mfccs done\n",
      "589  mfccs done\n",
      "590  mfccs done\n",
      "591  mfccs done\n",
      "592  mfccs done\n",
      "593  mfccs done\n",
      "594  mfccs done\n",
      "595  mfccs done\n",
      "596  mfccs done\n",
      "597  mfccs done\n",
      "598  mfccs done\n",
      "599  mfccs done\n",
      "600  mfccs done\n",
      "601  mfccs done\n",
      "602  mfccs done\n",
      "603  mfccs done\n",
      "604  mfccs done\n",
      "605  mfccs done\n",
      "606  mfccs done\n",
      "607  mfccs done\n",
      "608  mfccs done\n",
      "609  mfccs done\n",
      "610  mfccs done\n",
      "611  mfccs done\n",
      "612  mfccs done\n",
      "613  mfccs done\n",
      "614  mfccs done\n",
      "615  mfccs done\n",
      "616  mfccs done\n",
      "617  mfccs done\n",
      "618  mfccs done\n",
      "619  mfccs done\n",
      "620  mfccs done\n",
      "621  mfccs done\n",
      "622  mfccs done\n",
      "623  mfccs done\n",
      "624  mfccs done\n",
      "625  mfccs done\n",
      "626  mfccs done\n",
      "627  mfccs done\n",
      "628  mfccs done\n",
      "629  mfccs done\n",
      "630  mfccs done\n",
      "631  mfccs done\n",
      "632  mfccs done\n",
      "633  mfccs done\n",
      "634  mfccs done\n",
      "635  mfccs done\n",
      "636  mfccs done\n",
      "637  mfccs done\n",
      "638  mfccs done\n",
      "639  mfccs done\n",
      "640  mfccs done\n",
      "641  mfccs done\n",
      "642  mfccs done\n",
      "643  mfccs done\n",
      "644  mfccs done\n",
      "645  mfccs done\n",
      "646  mfccs done\n",
      "647  mfccs done\n",
      "648  mfccs done\n",
      "649  mfccs done\n",
      "650  mfccs done\n",
      "651  mfccs done\n",
      "652  mfccs done\n",
      "653  mfccs done\n",
      "654  mfccs done\n",
      "655  mfccs done\n",
      "656  mfccs done\n",
      "657  mfccs done\n",
      "658  mfccs done\n",
      "659  mfccs done\n",
      "660  mfccs done\n",
      "661  mfccs done\n",
      "662  mfccs done\n",
      "663  mfccs done\n",
      "664  mfccs done\n",
      "665  mfccs done\n",
      "666  mfccs done\n",
      "667  mfccs done\n",
      "668  mfccs done\n",
      "669  mfccs done\n",
      "670  mfccs done\n",
      "671  mfccs done\n",
      "672  mfccs done\n",
      "673  mfccs done\n",
      "674  mfccs done\n",
      "675  mfccs done\n",
      "676  mfccs done\n",
      "677  mfccs done\n",
      "678  mfccs done\n",
      "679  mfccs done\n",
      "680  mfccs done\n",
      "681  mfccs done\n",
      "682  mfccs done\n",
      "683  mfccs done\n",
      "684  mfccs done\n",
      "685  mfccs done\n",
      "686  mfccs done\n",
      "687  mfccs done\n",
      "688  mfccs done\n",
      "689  mfccs done\n",
      "690  mfccs done\n",
      "691  mfccs done\n",
      "692  mfccs done\n",
      "693  mfccs done\n",
      "694  mfccs done\n",
      "695  mfccs done\n",
      "696  mfccs done\n",
      "697  mfccs done\n",
      "698  mfccs done\n",
      "699  mfccs done\n",
      "700  mfccs done\n",
      "701  mfccs done\n",
      "702  mfccs done\n",
      "703  mfccs done\n",
      "704  mfccs done\n",
      "705  mfccs done\n",
      "706  mfccs done\n",
      "707  mfccs done\n",
      "708  mfccs done\n",
      "709  mfccs done\n",
      "710  mfccs done\n",
      "711  mfccs done\n",
      "712  mfccs done\n",
      "713  mfccs done\n",
      "714  mfccs done\n",
      "715  mfccs done\n",
      "716  mfccs done\n",
      "717  mfccs done\n",
      "718  mfccs done\n",
      "719  mfccs done\n",
      "720  mfccs done\n",
      "721  mfccs done\n",
      "722  mfccs done\n",
      "723  mfccs done\n",
      "724  mfccs done\n",
      "725  mfccs done\n",
      "726  mfccs done\n",
      "727  mfccs done\n",
      "728  mfccs done\n",
      "729  mfccs done\n",
      "730  mfccs done\n",
      "731  mfccs done\n",
      "732  mfccs done\n",
      "733  mfccs done\n",
      "734  mfccs done\n",
      "735  mfccs done\n",
      "736  mfccs done\n",
      "737  mfccs done\n",
      "738  mfccs done\n",
      "739  mfccs done\n",
      "740  mfccs done\n",
      "741  mfccs done\n",
      "742  mfccs done\n",
      "743  mfccs done\n",
      "744  mfccs done\n",
      "745  mfccs done\n",
      "746  mfccs done\n",
      "747  mfccs done\n",
      "748  mfccs done\n",
      "749  mfccs done\n",
      "750  mfccs done\n",
      "751  mfccs done\n",
      "752  mfccs done\n",
      "753  mfccs done\n",
      "754  mfccs done\n",
      "755  mfccs done\n",
      "756  mfccs done\n",
      "757  mfccs done\n",
      "758  mfccs done\n",
      "759  mfccs done\n",
      "760  mfccs done\n",
      "761  mfccs done\n",
      "762  mfccs done\n",
      "763  mfccs done\n",
      "764  mfccs done\n",
      "765  mfccs done\n",
      "766  mfccs done\n",
      "767  mfccs done\n",
      "768  mfccs done\n",
      "769  mfccs done\n",
      "770  mfccs done\n",
      "771  mfccs done\n",
      "772  mfccs done\n",
      "773  mfccs done\n",
      "774  mfccs done\n",
      "775  mfccs done\n",
      "776  mfccs done\n",
      "777  mfccs done\n",
      "778  mfccs done\n",
      "779  mfccs done\n",
      "780  mfccs done\n",
      "781  mfccs done\n",
      "782  mfccs done\n",
      "783  mfccs done\n",
      "784  mfccs done\n",
      "785  mfccs done\n",
      "786  mfccs done\n",
      "787  mfccs done\n",
      "788  mfccs done\n",
      "789  mfccs done\n",
      "790  mfccs done\n",
      "791  mfccs done\n",
      "792  mfccs done\n",
      "793  mfccs done\n",
      "794  mfccs done\n",
      "795  mfccs done\n",
      "796  mfccs done\n",
      "797  mfccs done\n",
      "798  mfccs done\n",
      "799  mfccs done\n",
      "800  mfccs done\n",
      "801  mfccs done\n",
      "802  mfccs done\n",
      "803  mfccs done\n",
      "804  mfccs done\n",
      "805  mfccs done\n",
      "806  mfccs done\n",
      "807  mfccs done\n",
      "808  mfccs done\n",
      "809  mfccs done\n",
      "810  mfccs done\n",
      "811  mfccs done\n",
      "812  mfccs done\n",
      "813  mfccs done\n",
      "814  mfccs done\n",
      "815  mfccs done\n",
      "816  mfccs done\n",
      "817  mfccs done\n",
      "818  mfccs done\n",
      "819  mfccs done\n",
      "820  mfccs done\n",
      "821  mfccs done\n",
      "822  mfccs done\n",
      "823  mfccs done\n",
      "824  mfccs done\n",
      "825  mfccs done\n",
      "826  mfccs done\n",
      "827  mfccs done\n",
      "828  mfccs done\n",
      "829  mfccs done\n",
      "830  mfccs done\n",
      "831  mfccs done\n",
      "832  mfccs done\n",
      "833  mfccs done\n",
      "834  mfccs done\n",
      "835  mfccs done\n",
      "836  mfccs done\n",
      "837  mfccs done\n",
      "838  mfccs done\n",
      "839  mfccs done\n",
      "840  mfccs done\n",
      "841  mfccs done\n",
      "842  mfccs done\n",
      "843  mfccs done\n",
      "844  mfccs done\n",
      "845  mfccs done\n",
      "846  mfccs done\n",
      "847  mfccs done\n",
      "848  mfccs done\n",
      "849  mfccs done\n",
      "850  mfccs done\n",
      "851  mfccs done\n",
      "852  mfccs done\n",
      "853  mfccs done\n",
      "854  mfccs done\n",
      "855  mfccs done\n",
      "856  mfccs done\n",
      "857  mfccs done\n",
      "858  mfccs done\n",
      "859  mfccs done\n",
      "860  mfccs done\n",
      "861  mfccs done\n",
      "862  mfccs done\n",
      "863  mfccs done\n",
      "864  mfccs done\n",
      "865  mfccs done\n",
      "866  mfccs done\n",
      "867  mfccs done\n",
      "868  mfccs done\n",
      "869  mfccs done\n",
      "870  mfccs done\n",
      "871  mfccs done\n",
      "872  mfccs done\n",
      "873  mfccs done\n",
      "874  mfccs done\n",
      "875  mfccs done\n",
      "876  mfccs done\n",
      "877  mfccs done\n",
      "878  mfccs done\n",
      "879  mfccs done\n",
      "880  mfccs done\n",
      "881  mfccs done\n",
      "882  mfccs done\n",
      "883  mfccs done\n",
      "884  mfccs done\n",
      "885  mfccs done\n",
      "886  mfccs done\n",
      "887  mfccs done\n",
      "888  mfccs done\n",
      "889  mfccs done\n",
      "890  mfccs done\n",
      "891  mfccs done\n",
      "892  mfccs done\n",
      "893  mfccs done\n",
      "894  mfccs done\n",
      "895  mfccs done\n",
      "896  mfccs done\n",
      "897  mfccs done\n",
      "898  mfccs done\n",
      "899  mfccs done\n",
      "900  mfccs done\n",
      "901  mfccs done\n",
      "902  mfccs done\n",
      "903  mfccs done\n",
      "904  mfccs done\n",
      "905  mfccs done\n",
      "906  mfccs done\n",
      "907  mfccs done\n",
      "908  mfccs done\n",
      "909  mfccs done\n",
      "910  mfccs done\n",
      "911  mfccs done\n",
      "912  mfccs done\n",
      "913  mfccs done\n",
      "914  mfccs done\n",
      "915  mfccs done\n",
      "916  mfccs done\n",
      "917  mfccs done\n",
      "918  mfccs done\n",
      "919  mfccs done\n",
      "920  mfccs done\n",
      "921  mfccs done\n",
      "922  mfccs done\n",
      "923  mfccs done\n",
      "924  mfccs done\n",
      "925  mfccs done\n",
      "926  mfccs done\n",
      "927  mfccs done\n",
      "928  mfccs done\n",
      "929  mfccs done\n",
      "930  mfccs done\n",
      "931  mfccs done\n",
      "932  mfccs done\n",
      "933  mfccs done\n",
      "934  mfccs done\n",
      "935  mfccs done\n",
      "936  mfccs done\n",
      "937  mfccs done\n",
      "938  mfccs done\n",
      "939  mfccs done\n",
      "940  mfccs done\n",
      "941  mfccs done\n",
      "942  mfccs done\n",
      "943  mfccs done\n",
      "944  mfccs done\n",
      "945  mfccs done\n",
      "946  mfccs done\n",
      "947  mfccs done\n",
      "948  mfccs done\n",
      "949  mfccs done\n",
      "950  mfccs done\n",
      "951  mfccs done\n",
      "952  mfccs done\n",
      "953  mfccs done\n",
      "954  mfccs done\n",
      "955  mfccs done\n",
      "956  mfccs done\n",
      "957  mfccs done\n",
      "958  mfccs done\n",
      "959  mfccs done\n",
      "960  mfccs done\n",
      "961  mfccs done\n",
      "962  mfccs done\n",
      "963  mfccs done\n",
      "964  mfccs done\n",
      "965  mfccs done\n",
      "966  mfccs done\n",
      "967  mfccs done\n",
      "968  mfccs done\n",
      "969  mfccs done\n",
      "970  mfccs done\n",
      "971  mfccs done\n",
      "972  mfccs done\n",
      "973  mfccs done\n",
      "974  mfccs done\n",
      "975  mfccs done\n",
      "976  mfccs done\n",
      "977  mfccs done\n",
      "978  mfccs done\n",
      "979  mfccs done\n",
      "980  mfccs done\n",
      "981  mfccs done\n",
      "982  mfccs done\n",
      "983  mfccs done\n",
      "984  mfccs done\n",
      "985  mfccs done\n",
      "986  mfccs done\n",
      "987  mfccs done\n",
      "988  mfccs done\n",
      "989  mfccs done\n",
      "990  mfccs done\n",
      "991  mfccs done\n",
      "992  mfccs done\n",
      "993  mfccs done\n",
      "994  mfccs done\n",
      "995  mfccs done\n",
      "996  mfccs done\n",
      "997  mfccs done\n",
      "998  mfccs done\n",
      "999  mfccs done\n",
      "1000  mfccs done\n",
      "1001  mfccs done\n",
      "1002  mfccs done\n",
      "1003  mfccs done\n",
      "1004  mfccs done\n",
      "1005  mfccs done\n",
      "1006  mfccs done\n",
      "1007  mfccs done\n",
      "1008  mfccs done\n",
      "1009  mfccs done\n",
      "1010  mfccs done\n",
      "1011  mfccs done\n",
      "1012  mfccs done\n",
      "1013  mfccs done\n",
      "1014  mfccs done\n",
      "1015  mfccs done\n",
      "1016  mfccs done\n",
      "1017  mfccs done\n",
      "1018  mfccs done\n",
      "1019  mfccs done\n",
      "1020  mfccs done\n",
      "1021  mfccs done\n",
      "1022  mfccs done\n",
      "1023  mfccs done\n",
      "1024  mfccs done\n",
      "1025  mfccs done\n",
      "1026  mfccs done\n",
      "1027  mfccs done\n",
      "1028  mfccs done\n",
      "1029  mfccs done\n",
      "1030  mfccs done\n",
      "1031  mfccs done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032  mfccs done\n",
      "1033  mfccs done\n",
      "1034  mfccs done\n",
      "1035  mfccs done\n",
      "1036  mfccs done\n",
      "1037  mfccs done\n",
      "1038  mfccs done\n",
      "1039  mfccs done\n",
      "1040  mfccs done\n",
      "1041  mfccs done\n",
      "1042  mfccs done\n",
      "1043  mfccs done\n",
      "1044  mfccs done\n",
      "1045  mfccs done\n",
      "1046  mfccs done\n",
      "1047  mfccs done\n",
      "1048  mfccs done\n",
      "1049  mfccs done\n",
      "1050  mfccs done\n",
      "1051  mfccs done\n",
      "1052  mfccs done\n",
      "1053  mfccs done\n",
      "1054  mfccs done\n",
      "1055  mfccs done\n",
      "1056  mfccs done\n",
      "1057  mfccs done\n",
      "1058  mfccs done\n",
      "1059  mfccs done\n",
      "1060  mfccs done\n",
      "1061  mfccs done\n",
      "1062  mfccs done\n",
      "1063  mfccs done\n",
      "1064  mfccs done\n",
      "1065  mfccs done\n",
      "1066  mfccs done\n",
      "1067  mfccs done\n",
      "1068  mfccs done\n",
      "1069  mfccs done\n",
      "1070  mfccs done\n",
      "1071  mfccs done\n",
      "1072  mfccs done\n",
      "1073  mfccs done\n",
      "1074  mfccs done\n",
      "1075  mfccs done\n",
      "1076  mfccs done\n",
      "1077  mfccs done\n",
      "1078  mfccs done\n",
      "1079  mfccs done\n",
      "1080  mfccs done\n",
      "1081  mfccs done\n",
      "1082  mfccs done\n",
      "1083  mfccs done\n",
      "1084  mfccs done\n",
      "1085  mfccs done\n",
      "1086  mfccs done\n",
      "1087  mfccs done\n",
      "1088  mfccs done\n",
      "1089  mfccs done\n",
      "1090  mfccs done\n",
      "1091  mfccs done\n",
      "1092  mfccs done\n",
      "1093  mfccs done\n",
      "1094  mfccs done\n",
      "1095  mfccs done\n",
      "1096  mfccs done\n",
      "1097  mfccs done\n",
      "1098  mfccs done\n",
      "1099  mfccs done\n",
      "1100  mfccs done\n",
      "1101  mfccs done\n",
      "1102  mfccs done\n",
      "1103  mfccs done\n",
      "1104  mfccs done\n",
      "1105  mfccs done\n",
      "1106  mfccs done\n",
      "1107  mfccs done\n",
      "1108  mfccs done\n",
      "1109  mfccs done\n",
      "1110  mfccs done\n",
      "1111  mfccs done\n",
      "1112  mfccs done\n",
      "1113  mfccs done\n",
      "1114  mfccs done\n",
      "1115  mfccs done\n",
      "1116  mfccs done\n",
      "1117  mfccs done\n",
      "1118  mfccs done\n",
      "1119  mfccs done\n",
      "1120  mfccs done\n",
      "1121  mfccs done\n",
      "1122  mfccs done\n",
      "1123  mfccs done\n",
      "1124  mfccs done\n",
      "1125  mfccs done\n",
      "1126  mfccs done\n",
      "1127  mfccs done\n",
      "1128  mfccs done\n",
      "1129  mfccs done\n",
      "1130  mfccs done\n",
      "1131  mfccs done\n",
      "1132  mfccs done\n",
      "1133  mfccs done\n",
      "1134  mfccs done\n",
      "1135  mfccs done\n",
      "1136  mfccs done\n",
      "1137  mfccs done\n",
      "1138  mfccs done\n",
      "1139  mfccs done\n",
      "1140  mfccs done\n",
      "1141  mfccs done\n",
      "1142  mfccs done\n",
      "1143  mfccs done\n",
      "1144  mfccs done\n",
      "1145  mfccs done\n",
      "1146  mfccs done\n",
      "1147  mfccs done\n",
      "1148  mfccs done\n",
      "1149  mfccs done\n",
      "1150  mfccs done\n",
      "1151  mfccs done\n",
      "1152  mfccs done\n",
      "1153  mfccs done\n",
      "1154  mfccs done\n",
      "1155  mfccs done\n",
      "1156  mfccs done\n",
      "1157  mfccs done\n",
      "1158  mfccs done\n",
      "1159  mfccs done\n",
      "1160  mfccs done\n",
      "1161  mfccs done\n",
      "1162  mfccs done\n",
      "1163  mfccs done\n",
      "1164  mfccs done\n",
      "1165  mfccs done\n",
      "1166  mfccs done\n",
      "1167  mfccs done\n",
      "1168  mfccs done\n",
      "1169  mfccs done\n",
      "1170  mfccs done\n",
      "1171  mfccs done\n",
      "1172  mfccs done\n",
      "1173  mfccs done\n",
      "1174  mfccs done\n",
      "1175  mfccs done\n",
      "1176  mfccs done\n",
      "1177  mfccs done\n",
      "1178  mfccs done\n",
      "1179  mfccs done\n",
      "1180  mfccs done\n",
      "1181  mfccs done\n",
      "1182  mfccs done\n",
      "1183  mfccs done\n",
      "1184  mfccs done\n",
      "1185  mfccs done\n",
      "1186  mfccs done\n",
      "1187  mfccs done\n",
      "1188  mfccs done\n",
      "1189  mfccs done\n",
      "1190  mfccs done\n",
      "1191  mfccs done\n",
      "1192  mfccs done\n",
      "1193  mfccs done\n",
      "1194  mfccs done\n",
      "1195  mfccs done\n",
      "1196  mfccs done\n",
      "1197  mfccs done\n",
      "1198  mfccs done\n",
      "1199  mfccs done\n",
      "1200  mfccs done\n",
      "1201  mfccs done\n"
     ]
    }
   ],
   "source": [
    "# REAL VECTORS, ALL FILES - SAVE\n",
    "\n",
    "mfccs_vectors = make_mfcc(folder_train)\n",
    "# store the mfccs as a pickle file \n",
    "with open(\"vectors.txt\", \"wb\") as fp:\n",
    "     pickle.dump(mfccs_vectors, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST VECTORS, ONLY 4 FILES - SAVE\n",
    "\n",
    "mfccs_vectors = make_mfcc(test_folder)\n",
    "# store the mfccs as a pickle file \n",
    "with open(\"test_vectors.txt\", \"wb\") as fp:\n",
    "     pickle.dump(mfccs_vectors, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD ALL MFCCS\n",
    "\n",
    "with open(\"vectors.txt\", \"rb\") as fp:\n",
    "     mfccs_vectors = pickle.load(fp)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_dataset(mfccs_vectors, k, m, SEED):\n",
    "    \"\"\"\n",
    "    Make a hashed dataset with parameters k and m and with the extracted mfccs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mfccs_vectors : numpy array\n",
    "        array of mfcc vector arrays extracted from an audio file, each array is a file\n",
    "    k : num\n",
    "        Number of units we randomly choose of the vector\n",
    "    m : num\n",
    "        Number of times we will do the hashing for some vector.\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        We return a list of numpy arrays, each representing a hashed audio file\n",
    "    \"\"\"\n",
    "    N = k*m\n",
    "    V =[]\n",
    "    p = hash_dim(N,k,m,SEED).astype(int)\n",
    "    for vect in mfccs_vectors:\n",
    "        v = get_hash(vect, k, m, p)\n",
    "        V.append(v) \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(T, V_train, V_test, N, U):\n",
    "    \"\"\"\n",
    "    Perform a precision recall test on chosen files and parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T : a numpy array T of shape (N, N)\n",
    "        Memory in form of a matrix (synaptic weights)\n",
    "    V_train : list of arrays (hashed features)\n",
    "        The data we train our memory system on\n",
    "    V_test : list of arrays (hashed features)\n",
    "        The data we tast the memory system on\n",
    "    N : num\n",
    "        N=k*m, where k is the number of zeros in the hashed vector, m is number of ones\n",
    "    U : num\n",
    "        Chosen threshold above which the neuron is active\n",
    "    Returns\n",
    "    -------\n",
    "    num\n",
    "        We return values of hits, false alarms, correct rejections, misses\n",
    "    \"\"\"\n",
    "    \n",
    "    hits = 0\n",
    "    false_alarm = 0\n",
    "    default = np.zeros(N)\n",
    "    for v in V_test:\n",
    "        memory = retrieve_memory(T, v, U=U, full_trace=False)\n",
    "        if np.array_equal(memory, default):\n",
    "            hits += 1\n",
    "        else:\n",
    "            false_alarm += 1\n",
    "    hits = hits/len(V_test)\n",
    "    false_alarm = false_alarm/len(V_test)\n",
    "\n",
    "    correct_rejection = 0\n",
    "    miss = 0\n",
    "    default = np.zeros(N)\n",
    "    for v in V_train:\n",
    "        memory = retrieve_memory(T, v, U=U, full_trace=False)\n",
    "        if np.array_equal(memory, default):\n",
    "            miss += 1\n",
    "        else:\n",
    "            correct_rejection += 1\n",
    "    correct_rejection = correct_rejection/len(V_train)\n",
    "    miss = miss/len(V_train)\n",
    "    \n",
    "    \n",
    "    return hits, false_alarm, correct_rejection, miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_for_N(k, minimum, maximum, num_points):\n",
    "    \"\"\"\n",
    "    Finds equally spaced values for N, from pre-defined minimum to \n",
    "    pre-defined maximum. N is the dimension of our memory storage \n",
    "    (which is of the size N*N).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k : num\n",
    "        Number of units we randomly choose of the vector\n",
    "    minimum : num\n",
    "        Minimum number we want the range to start from\n",
    "    maximum : num\n",
    "        Maximum number we want the range to stop at\n",
    "    num_points : nuim\n",
    "        The number of points we want between and including min and max\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        We return a list of the number num_points from min to max\n",
    "    \"\"\"\n",
    "    \n",
    "    minimum_ = np.ceil(minimum/k)\n",
    "    maximum_ = np.floor(maximum/k)\n",
    "    range_N = np.unique(np.round(np.linspace(minimum_, maximum_, num_points)).astype(int))\n",
    "    return k*range_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(int(1./(33./100.)))\n",
    "print(int(1/Fraction(10,100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "both arguments should be Rational instances",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-4979390ebafb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfractions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m33.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"m\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"U\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TPR\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FPR\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mSEED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/shennong/lib/python3.8/fractions.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, numerator, denominator, _normalize)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 )\n\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             raise TypeError(\"both arguments should be \"\n\u001b[0m\u001b[1;32m    175\u001b[0m                             \"Rational instances\")\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: both arguments should be Rational instances"
     ]
    }
   ],
   "source": [
    "from fractions import Fraction\n",
    "S = [Fraction(1,x) for x in range(2,100)]\n",
    "S = [Fraction(1,100), Fraction(10,100.), Fraction(33.,100.)]\n",
    "data = {\"k\":[], \"m\":[], \"U\":[], \"TPR\":[], \"FPR\":[]}\n",
    "SEED = 27\n",
    "minimum_N = 500\n",
    "maximum_N = 1000\n",
    "num_points_N = 3\n",
    "\n",
    "# for threshold in np.linspace(-1,5,25):\n",
    "for threshold in [0,1]:\n",
    "    for s in S:\n",
    "        k = int(1/s)\n",
    "        assert k == 1/s\n",
    "        N_list = range_for_N(k, minimum_N, maximum_N, num_points_N)\n",
    "        for N in N_list:\n",
    "            m = int(N/k)\n",
    "            assert m == N/k, (m,N/k)\n",
    "            print(\"k, m: \", k, m)\n",
    "            U = threshold*s*N\n",
    "            print(\"Threshold: \", threshold)\n",
    "            V = hash_dataset(mfccs_vectors, k, m, SEED)\n",
    "            V_train = V[:len(V)//2]\n",
    "            V_test = V[len(V)//2:]\n",
    "            T = initialize_network(N, V_train)\n",
    "            data[\"k\"].append(k)\n",
    "            data[\"m\"].append(m)\n",
    "            data[\"U\"].append(threshold)\n",
    "            hit, fa, corr_rej, miss = precision_recall(T, V_train, V_test, N, threshold)\n",
    "            if hit + miss == 0:\n",
    "                TPR = np.NaN\n",
    "            else:\n",
    "                TPR = hit / (hit + miss)\n",
    "            if fa + corr_rej == 0:\n",
    "                FPR = np.NaN\n",
    "            else:\n",
    "                FPR = fa / (fa + corr_rej)\n",
    "            data[\"TPR\"].append(TPR)\n",
    "            data[\"FPR\"].append(FPR)\n",
    "\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./TPR_FPR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>m</th>\n",
       "      <th>U</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1620 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       k   m        U  TPR  FPR\n",
       "0      2   2      1.0  NaN  0.5\n",
       "1      2   3      1.0  NaN  0.5\n",
       "2      2   4      1.0  NaN  0.5\n",
       "3      2   5      1.0  NaN  0.5\n",
       "4      2   6      1.0  NaN  0.5\n",
       "...   ..  ..      ...  ...  ...\n",
       "1615  10   6  10000.0  0.5  NaN\n",
       "1616  10   7  10000.0  0.5  NaN\n",
       "1617  10   8  10000.0  0.5  NaN\n",
       "1618  10   9  10000.0  0.5  NaN\n",
       "1619  10  10  10000.0  0.5  NaN\n",
       "\n",
       "[1620 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"./TPR_FPR.csv\", index_col=0)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>m</th>\n",
       "      <th>U</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [k, m, U, TPR, FPR]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.DataFrame(data)\n",
    "# data = data[(data['k'] <= 7) & (data['m'] <= 7)]\n",
    "data = data[data['TPR'].notna()]\n",
    "data = data[data['FPR'].notna()]\n",
    "g = seaborn.relplot(x=\"FPR\", y = \"TPR\", data = data, col = \"k\", row = \"m\")\n",
    "# plt.savefig('tpr_fpr.png')\n",
    "for ax in g.axes.flatten():\n",
    "    ax.grid()\n",
    "\n",
    "g.savefig('tpr_fpr_filtered.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Hopfield, J. J. (1982). Neural networks and physical systems with emergent collective computational abilities. Proceedings of the national academy of sciences, 79(8), 2554-2558. \n",
    "[https://doi.org/10.1073/pnas.79.8.2554]\n",
    "\n",
    "[2] Andoni, A., & Indyk, P. (2006, October). Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In 2006 47th annual IEEE symposium on foundations of computer science (FOCS'06) (pp. 459-468). IEEE.\n",
    "[https://10.1109/FOCS.2006.49]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
