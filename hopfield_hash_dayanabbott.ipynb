{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopfield Network With Hashing - Dayan & Abbott"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code takes as input .wav sound files and transforms each of them into MFCC vectors. These vectors are then each transformed into a hash. They are then used to train a Hopfield network. In this way, each sound vector becomes a memory pattern that can be accessed even if slightly corrupted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a memory mechanism in a form of a Hopfield network. The stored items are called memory patterns. They are retrieved by a process of the input that is presented to the network dynamics which at some time step reaches a fixed stable point. This means that the input item has been recognized (i.e. there is a memory pattern identical or very similar to it).\n",
    "\n",
    "Even noisy sounds or those corrupted to some extent can be accessed. In other words, if the input is $x_1 + \\delta$ and the stored item is $x_1$, the network will still reach the fixed point of $x_1$ if $\\delta$ is small enough.\n",
    "\n",
    "Additionally, for storage purposes, sounds are transformed each into a hash - with this we reduce their dimensionality. This means we increase the storage capacity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we load some dependencies.\n",
    "import numpy as np\n",
    "import math\n",
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "import sys\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with some wav files to test this script.\n",
    "folder_train = \"./waveforms/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to transform the sounds into a readable format that can be used for hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the folder and find all (and only) files ending with .wav\n",
    "# Here, we transform each .wav file into MFCCs and then flatten them into one vector\n",
    "# We do this because we want one hash per .wav file\n",
    "#\n",
    "# Arguments: sound folder\n",
    "# Returns: a list of flattened MFCC vectors\n",
    "\n",
    "def make_mfcc(folder):\n",
    "    vectors = []\n",
    "    for file in glob.glob(folder + \"*.wav\", recursive=True):\n",
    "        (rate,sig) = wav.read(file)\n",
    "        mfcc_feat = mfcc(sig,rate)\n",
    "        vect = mfcc_feat.flatten()\n",
    "        vectors.append(vect)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will transform each sound (that is, each sound transformed into MFCC vectors, then flattened into one vector) into a hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform a vector of speech into a hash\n",
    "# The hash will be a matrix of the dimension = k*m\n",
    "# We choose a random number k of units of the vector.\n",
    "# And look for the highest value and turn it into 1.\n",
    "# Everything else is 0.\n",
    "# We thus get sparse matrices.\n",
    "# We do this m times. Final output is h=k*m.\n",
    "\n",
    "\n",
    "def get_hash(vector, k, m):\n",
    "    d = len(vector)\n",
    "    p = np.zeros((m,k,))\n",
    "    for i in range(m):\n",
    "        p[i] = np.random.permutation(d)[:k]\n",
    "        \n",
    "    h = np.zeros((m,k,))\n",
    "    for i in range(m):\n",
    "        ix = np.argmax(p[i])\n",
    "        hi = np.zeros(k)\n",
    "        hi[ix] = 1\n",
    "        h[i] = hi\n",
    "    h = np.hstack(h)\n",
    "    return h\n",
    "\n",
    "## Test:\n",
    "# V = make_mfcc(folder)\n",
    "# get_hash(V[1], 5, 3)\n",
    "\n",
    "# Principle\n",
    "# - Algo: inputs of dimension d, params k, m (hash dim=k*m)\n",
    "#   - pre-processing: \n",
    "#       p=[]; \n",
    "#       for i=1:m: \n",
    "#           p[i] = random_perm(d)[:k]\n",
    "#   - getting hash for X: \n",
    "#       h = []\n",
    "#       for i=1:m:\n",
    "#         ix = argmax(X[p[i]])\n",
    "#         hi = zeros(k)\n",
    "#         hi[ix] = 1\n",
    "#         h = h + hi\n",
    "#   -> i.e. there is a local WTA on m sets of \n",
    "#   randomly chosen k-tuple of dims -> hash is of length mk with exactly m ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopfield network consists of a symmetric recurrent weight matrix that is trained with memory patterns (presented as hash vectors) we want to store. The weight matrix is trained with those patterns such that each of them becomes a fixed point of the network. Once we want to \"retrieve\" a memory pattern, we need to find one of the fixed points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the matrix M (symmetric recurrent weight matrix)\n",
    "#\n",
    "# Arguments: \n",
    "# lmbda (eigenvalue represented as a lambda), alpha (amount of active units),\n",
    "# c (constant value of active components, inactive have 0), \n",
    "# N (number of neurons), V (list of vectors in a hash form)\n",
    "\n",
    "def get_m(lmbda, alpha, c, N, V):\n",
    "    \n",
    "    # n is a vector of ones\n",
    "    n = np.ones(N)\n",
    "\n",
    "    vect_sum = np.zeros((N,N))\n",
    "    for vect in V:\n",
    "        outer_prod = np.outer((vect - alpha * c * n),(vect - alpha * c * n))\n",
    "        vect_sum += outer_prod\n",
    "\n",
    "    m = (lmbda / (pow(c,2)*alpha*N*(1-alpha))) \\\n",
    "        * vect_sum \\\n",
    "        - (np.outer(n,n) / (alpha*N))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to determine what is a fixed point of the network. This is done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the fixed point\n",
    "# Memory pattern satisfies v_m = F(M * v_m) (i.e. is a fixed point)\n",
    "# We use a sigmoid function as F: F = 1/(1+np.exp(-x))\n",
    "\n",
    "def convergence_criterion(x0, x1, tau):\n",
    "#     return math.isclose(x0, x1, rel_tol=tau) \n",
    "    return np.allclose(x0, x1, rtol=tau)\n",
    "\n",
    "def fixed_point(x0, m, tau, i):\n",
    "    x1 = 1/(1 + np.exp(- np.inner(m,x0) ))\n",
    "    while convergence_criterion(x0, x1, tau) == False:\n",
    "        i += 1\n",
    "        return fixed_point(x1, m, tau, i)\n",
    "    print(i)\n",
    "    return x1\n",
    "\n",
    "#     if F == None:\n",
    "#         x1 = 1/(1 + np.exp(- np.inner(m,x0) ))\n",
    "#     else:\n",
    "#         x1 = F*x0\n",
    "    \n",
    "#     if convergence_criterion(x0, x1, tau):\n",
    "#         return x1\n",
    "#     else:\n",
    "#         i += 1\n",
    "#         print(i)\n",
    "#         return fixed_point(x1, tau, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    }
   ],
   "source": [
    "# Test:\n",
    "\n",
    "k = 5\n",
    "m = 3\n",
    "lmbda = 0.1\n",
    "alpha = 0.6\n",
    "c = 1\n",
    "N = 15\n",
    "V =[]\n",
    "\n",
    "mfccs_vectors = make_mfcc(folder_train)\n",
    "for vect in mfccs_vectors:\n",
    "    v = get_hash(vect, 5, 3)\n",
    "    V.append(v)\n",
    "\n",
    "m = get_m(lmbda, alpha, c, N, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "[0.39334329 0.40984807 0.37696892 0.3932346  0.4100676  0.40984807\n",
      " 0.40973644 0.39355551 0.4100676  0.36077461 0.37783568 0.4100676\n",
      " 0.40973201 0.42588487 0.36087596]\n",
      "2\n",
      "[0.39675003 0.41283273 0.38077336 0.39663041 0.41307817 0.41283273\n",
      " 0.4127123  0.39697942 0.41307817 0.36494006 0.38169337 0.41307817\n",
      " 0.41271117 0.42838444 0.36505202]\n",
      "11\n",
      "[0.39334336 0.40984814 0.37696901 0.39323467 0.41006766 0.40984814\n",
      " 0.4097365  0.39355558 0.41006766 0.36077469 0.37783576 0.41006766\n",
      " 0.40973207 0.42588493 0.36087605]\n",
      "3\n",
      "[0.39589927 0.41209422 0.37981404 0.39578245 0.41232934 0.41209422\n",
      " 0.41197482 0.39612637 0.41232934 0.36388323 0.38073501 0.41232934\n",
      " 0.41197149 0.42776497 0.3639927 ]\n"
     ]
    }
   ],
   "source": [
    "# Test to get to fixed poind\n",
    "\n",
    "tau1 = 0.000001\n",
    "tau2 = 0.1\n",
    "# x0_1 is a vector similar to a memory pattern that is stored\n",
    "x0_1 = np.array([0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.])\n",
    "# x0_2 is a vector very different from any memory pattern stored\n",
    "x0_2 = np.array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
    "\n",
    "print(fixed_point(x0_1, m, tau1, 0))\n",
    "\n",
    "print(fixed_point(x0_1, m, tau2, 0))\n",
    "\n",
    "# This is problematic: x0_2 is not even nearly similar to any of the stored patterns, \n",
    "# yet w reach the local minimum/fixed point\n",
    "\n",
    "print(fixed_point(x0_2, m, tau1, 0))\n",
    "\n",
    "print(fixed_point(x0_2, m, tau2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03222222 -0.07111111 -0.10444444 -0.08777778 -0.07111111 -0.07111111\n",
      "  -0.04333333 -0.08777778 -0.07111111 -0.09333333 -0.07666667 -0.07111111\n",
      "  -0.07111111 -0.05444444 -0.09333333]\n",
      " [-0.07111111 -0.02666667 -0.08777778 -0.07111111 -0.05444444 -0.02666667\n",
      "  -0.05444444 -0.07111111 -0.05444444 -0.10444444 -0.06       -0.05444444\n",
      "  -0.05444444 -0.03777778 -0.10444444]\n",
      " [-0.10444444 -0.08777778 -0.03777778 -0.10444444 -0.08777778 -0.08777778\n",
      "  -0.08777778 -0.07666667 -0.08777778 -0.08222222 -0.12111111 -0.08777778\n",
      "  -0.06       -0.07111111 -0.08222222]\n",
      " [-0.08777778 -0.07111111 -0.10444444 -0.03222222 -0.07111111 -0.07111111\n",
      "  -0.07111111 -0.06       -0.07111111 -0.09333333 -0.07666667 -0.07111111\n",
      "  -0.07111111 -0.05444444 -0.09333333]\n",
      " [-0.07111111 -0.05444444 -0.08777778 -0.07111111 -0.02666667 -0.05444444\n",
      "  -0.05444444 -0.07111111 -0.02666667 -0.10444444 -0.08777778 -0.02666667\n",
      "  -0.05444444 -0.03777778 -0.10444444]\n",
      " [-0.07111111 -0.02666667 -0.08777778 -0.07111111 -0.05444444 -0.02666667\n",
      "  -0.05444444 -0.07111111 -0.05444444 -0.10444444 -0.06       -0.05444444\n",
      "  -0.05444444 -0.03777778 -0.10444444]\n",
      " [-0.04333333 -0.05444444 -0.08777778 -0.07111111 -0.05444444 -0.05444444\n",
      "  -0.02666667 -0.07111111 -0.05444444 -0.10444444 -0.06       -0.05444444\n",
      "  -0.05444444 -0.03777778 -0.10444444]\n",
      " [-0.08777778 -0.07111111 -0.07666667 -0.06       -0.07111111 -0.07111111\n",
      "  -0.07111111 -0.03222222 -0.07111111 -0.12111111 -0.10444444 -0.07111111\n",
      "  -0.04333333 -0.05444444 -0.09333333]\n",
      " [-0.07111111 -0.05444444 -0.08777778 -0.07111111 -0.02666667 -0.05444444\n",
      "  -0.05444444 -0.07111111 -0.02666667 -0.10444444 -0.08777778 -0.02666667\n",
      "  -0.05444444 -0.03777778 -0.10444444]\n",
      " [-0.09333333 -0.10444444 -0.08222222 -0.09333333 -0.10444444 -0.10444444\n",
      "  -0.10444444 -0.12111111 -0.10444444 -0.04333333 -0.11       -0.10444444\n",
      "  -0.10444444 -0.08777778 -0.07111111]\n",
      " [-0.07666667 -0.06       -0.12111111 -0.07666667 -0.08777778 -0.06\n",
      "  -0.06       -0.10444444 -0.08777778 -0.11       -0.03777778 -0.08777778\n",
      "  -0.08777778 -0.07111111 -0.13777778]\n",
      " [-0.07111111 -0.05444444 -0.08777778 -0.07111111 -0.02666667 -0.05444444\n",
      "  -0.05444444 -0.07111111 -0.02666667 -0.10444444 -0.08777778 -0.02666667\n",
      "  -0.05444444 -0.03777778 -0.10444444]\n",
      " [-0.07111111 -0.05444444 -0.06       -0.07111111 -0.05444444 -0.05444444\n",
      "  -0.05444444 -0.04333333 -0.05444444 -0.10444444 -0.08777778 -0.05444444\n",
      "  -0.02666667 -0.03777778 -0.10444444]\n",
      " [-0.05444444 -0.03777778 -0.07111111 -0.05444444 -0.03777778 -0.03777778\n",
      "  -0.03777778 -0.05444444 -0.03777778 -0.08777778 -0.07111111 -0.03777778\n",
      "  -0.03777778 -0.02111111 -0.08777778]\n",
      " [-0.09333333 -0.10444444 -0.08222222 -0.09333333 -0.10444444 -0.10444444\n",
      "  -0.10444444 -0.09333333 -0.10444444 -0.07111111 -0.13777778 -0.10444444\n",
      "  -0.10444444 -0.08777778 -0.04333333]]\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
