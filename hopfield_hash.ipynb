{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hopfield Network With Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code takes as input .wav sound files and transforms each of them into MFCC vectors. These vectors are then each transformed into a hash. They are then used to train a Hopfield network. In this way, each sound vector becomes a memory pattern that can be accessed even if slightly corrupted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is that if memory works as a Hopfield network with memory patterns being fixed points of the network, even noisy sounds or those corrupted to some extent can be accessed. Additionally, sounds are transformed each into a hash - with this we reduce their dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we load some dependencies.\n",
    "import numpy as np\n",
    "import math\n",
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "import sys\n",
    "import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with some wav files to test this script.\n",
    "folder = \"./waveforms/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to transform the sounds into a readable format that can be used for hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the folder and find all (and only) files ending with .wav\n",
    "# Here, we transform each .wav file into MFCCs and then flatten them into one vector\n",
    "# We do this because we want one hash per .wav file\n",
    "#\n",
    "# Arguments: sound folder\n",
    "# Returns: a list of flattened MFCC vectors\n",
    "\n",
    "def make_mfcc(folder):\n",
    "    V = []\n",
    "    for file in glob.glob(folder + \"*.wav\", recursive=True):\n",
    "        (rate,sig) = wav.read(file)\n",
    "        mfcc_feat = mfcc(sig,rate)\n",
    "        vect = mfcc_feat.flatten()\n",
    "        V.append(vect)\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will transform each sound (that is, each sound transformed into MFCC vectors, then flattened into one vector) into a hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform a vector of speech into a hash\n",
    "# The hash will be a matrix of the dimension = k*m\n",
    "# We choose a random number k of units of the vector.\n",
    "# And look for the highest value and turn it into 1.\n",
    "# Everything else is 0.\n",
    "# We thus get sparse matrices.\n",
    "# We do this m times. Final output is h=k*m.\n",
    "\n",
    "\n",
    "def get_hash(vector, k, m):\n",
    "    d = len(vector)\n",
    "    p = np.zeros((m,k,))\n",
    "    for i in range(m):\n",
    "        p[i] = np.random.permutation(d)[:k]\n",
    "        \n",
    "    h = np.zeros((m,k,))\n",
    "    for i in range(m):\n",
    "        ix = np.argmax(p[i])\n",
    "        hi = np.zeros(k)\n",
    "        hi[ix] = 1\n",
    "        h[i] = hi\n",
    "    h = np.hstack(h)\n",
    "    return h\n",
    "\n",
    "## Test:\n",
    "# V = make_mfcc(folder)\n",
    "# get_hash(V[1], 5, 3)\n",
    "\n",
    "# Principle\n",
    "# - Algo: inputs of dimension d, params k, m (hash dim=k*m)\n",
    "#   - pre-processing: \n",
    "#       p=[]; \n",
    "#       for i=1:m: \n",
    "#           p[i] = random_perm(d)[:k]\n",
    "#   - getting hash for X: \n",
    "#       h = []\n",
    "#       for i=1:m:\n",
    "#         ix = argmax(X[p[i]])\n",
    "#         hi = zeros(k)\n",
    "#         hi[ix] = 1\n",
    "#         h = h + hi\n",
    "#   -> i.e. there is a local WTA on m sets of \n",
    "#   randomly chosen k-tuple of dims -> hash is of length mk with exactly m ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopfield network consists of a symmetric recurrent weight matrix that is trained with memory patterns (presented as hash vectors) we want to store. The weight matrix is trained with those patterns such that each of them becomes a fixed point of the network. Once we want to \"retrieve\" a memory pattern, we need to find one of the fixed points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the matrix M (symmetric recurrent weight matrix)\n",
    "#\n",
    "# Arguments: \n",
    "# lmbda (eigenvalue represented as a lambda), alpha (amount of active units),\n",
    "# c (constant value of active components, inactive have 0), \n",
    "# N (number of neurons), V (list of vectors in a hash form)\n",
    "\n",
    "def get_m(lmbda, alpha, c, N, V):\n",
    "    \n",
    "    # n is a vector of ones\n",
    "    n = np.ones(N)\n",
    "\n",
    "    vect_sum = np.zeros(N)\n",
    "    for vect in V:\n",
    "        vect_sum = np.sum([vect_sum, vect], axis=0)\n",
    "    m = (lmbda / (pow(c,2)*alpha*N*(1-alpha))) \\\n",
    "        * vect_sum \\\n",
    "        - (np.outer(n,n) / (alpha*N))\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to determine what is a fixed point of the network. This is done by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the fixed point\n",
    "# Memory pattern satisfies v_m = F(M * v_m) (i.e. is a fixed point)\n",
    "# \n",
    "\n",
    "def convergence_criterion(x0, x1, tau):\n",
    "    return math.isclose(x0, x1, rel_tol=tau) \n",
    "\n",
    "def fixed_point(F, x0, tau):\n",
    "    print(F.shape)\n",
    "    print(x0.shape)\n",
    "    x1 = F.dot(x0)\n",
    "    if convergence_criterion(x0, x1, tau):\n",
    "        return x1\n",
    "    else:\n",
    "        return fixed_point(F, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n",
      "WARNING:root:frame length (800) is greater than FFT size (512), frame will be truncated. Increase NFFT to avoid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash:  [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "(10, 10)\n",
      "(15,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10,10) and (15,) not aligned: 10 (dim 1) != 15 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-930a16859de8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hash: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#     print(\"matrix m\", m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-8c8942e43d4f>\u001b[0m in \u001b[0;36mfixed_point\u001b[0;34m(F, x0, tau)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconvergence_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (10,10) and (15,) not aligned: 10 (dim 1) != 15 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Test:\n",
    "\n",
    "k = 5\n",
    "m = 3\n",
    "lmbda = 0.1\n",
    "alpha = 0.6\n",
    "c = 1\n",
    "N = 10\n",
    "\n",
    "mfccs_vectors = make_mfcc(folder)\n",
    "for v in mfccs_vectors:\n",
    "    V = get_hash(v, 5, 3)\n",
    "    print(\"hash: \", V)\n",
    "    m = get_m(lmbda, alpha, c, N, V)\n",
    "    f = fixed_point(m, V, 0.001)\n",
    "#     print(\"matrix m\", m)\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
